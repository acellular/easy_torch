{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## easy_torch usage examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional neural network trained on CIFAR100 Dataset loaded from torchvision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### CIFAR100 ################\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataset classes : \n",
      " ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# import CIFAR100 Dataset\n",
    "print('######### CIFAR100 ################')\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                    download=True, transform=transform)\n",
    "\n",
    "# convert to DataLoaders\n",
    "batch_size = 64\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "print(\"Dataset classes : \\n\",trainset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network design:  EasyTorchConv(\n",
      "  (net): ModuleDict(\n",
      "    (layer_1): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batchNorm_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation_1): ELU(alpha=1.0, inplace=True)\n",
      "    (layer_2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batchNorm_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation_2): ELU(alpha=1.0, inplace=True)\n",
      "    (maxPool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (dropout_2): Dropout(p=0.5, inplace=False)\n",
      "    (layer_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batchNorm_3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation_3): ELU(alpha=1.0, inplace=True)\n",
      "    (residual_3): Sequential(\n",
      "      (layer_0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchNorm_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation_0): ELU(alpha=1.0, inplace=True)\n",
      "      (layer_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchNorm_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation_1): ELU(alpha=1.0, inplace=True)\n",
      "    )\n",
      "    (maxPool_3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (dropout_3): Dropout(p=0.5, inplace=False)\n",
      "    (layer_4): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batchNorm_4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation_4): ELU(alpha=1.0, inplace=True)\n",
      "    (residual_4): Sequential(\n",
      "      (layer_0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchNorm_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation_0): ELU(alpha=1.0, inplace=True)\n",
      "      (layer_1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchNorm_1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation_1): ELU(alpha=1.0, inplace=True)\n",
      "    )\n",
      "    (maxPool_4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (dropout_4): Dropout(p=0.5, inplace=False)\n",
      "    (layer_5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batchNorm_5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation_5): ELU(alpha=1.0, inplace=True)\n",
      "    (residual_5): Sequential(\n",
      "      (layer_0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchNorm_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation_0): ELU(alpha=1.0, inplace=True)\n",
      "      (layer_1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchNorm_1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation_1): ELU(alpha=1.0, inplace=True)\n",
      "    )\n",
      "    (maxPool_5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (dropout_5): Dropout(p=0.5, inplace=False)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (output): Linear(in_features=4096, out_features=100, bias=True)\n",
      "  )\n",
      ")\n",
      "#### Start training: ####\n",
      "Device: cuda\n",
      "Training...\n",
      "Epoch 0: Train loss: 3.884, accuracy: 0.126 :: Test loss: 3.209 accuracy: 0.222\n",
      "Epoch 1: Train loss: 3.016, accuracy: 0.255 :: Test loss: 2.592 accuracy: 0.334\n",
      "Epoch 2: Train loss: 2.569, accuracy: 0.343 :: Test loss: 2.276 accuracy: 0.409\n",
      "Epoch 3: Train loss: 2.301, accuracy: 0.397 :: Test loss: 2.065 accuracy: 0.456\n",
      "Epoch 4: Train loss: 2.100, accuracy: 0.441 :: Test loss: 1.914 accuracy: 0.483\n",
      "Epoch 5: Train loss: 1.933, accuracy: 0.477 :: Test loss: 1.851 accuracy: 0.500\n",
      "Epoch 6: Train loss: 1.799, accuracy: 0.511 :: Test loss: 1.799 accuracy: 0.514\n",
      "Epoch 7: Train loss: 1.680, accuracy: 0.538 :: Test loss: 1.731 accuracy: 0.531\n",
      "Epoch 8: Train loss: 1.572, accuracy: 0.560 :: Test loss: 1.624 accuracy: 0.553\n",
      "Epoch 9: Train loss: 1.481, accuracy: 0.582 :: Test loss: 1.599 accuracy: 0.565\n",
      "Epoch 10: Train loss: 1.408, accuracy: 0.600 :: Test loss: 1.557 accuracy: 0.575\n",
      "Epoch 11: Train loss: 1.313, accuracy: 0.625 :: Test loss: 1.480 accuracy: 0.589\n",
      "Epoch 12: Train loss: 1.255, accuracy: 0.638 :: Test loss: 1.479 accuracy: 0.595\n",
      "Epoch 13: Train loss: 1.181, accuracy: 0.656 :: Test loss: 1.460 accuracy: 0.600\n",
      "Epoch 14: Train loss: 1.118, accuracy: 0.673 :: Test loss: 1.431 accuracy: 0.611\n",
      "Epoch 15: Train loss: 1.061, accuracy: 0.689 :: Test loss: 1.424 accuracy: 0.617\n",
      "Epoch 16: Train loss: 1.008, accuracy: 0.700 :: Test loss: 1.416 accuracy: 0.616\n",
      "Epoch 17: Train loss: 0.952, accuracy: 0.713 :: Test loss: 1.395 accuracy: 0.625\n",
      "Epoch 18: Train loss: 0.894, accuracy: 0.729 :: Test loss: 1.391 accuracy: 0.624\n",
      "Epoch 19: Train loss: 0.855, accuracy: 0.742 :: Test loss: 1.416 accuracy: 0.626\n",
      "Training finished.\n",
      "Final train loss: 0.855 :: accuracy: 0.742\n",
      "Final test loss: 1.416 :: accuracy: 0.626\n"
     ]
    }
   ],
   "source": [
    "# Train a convolutional network on the CIFAR100 Dataset\n",
    "from easy_torch import EasyTorchConv\n",
    "\n",
    "# create the convolutional network with residual layers: first layer is the channel number\n",
    "covn = EasyTorchConv(len(trainset.classes), conv_layer_sizes=(3,256,512,512,1024,1024),\n",
    "                    full_layer_sizes=(4096,), residual_inserts=(3,4,5), batch_norm=True, actv_func=torch.nn.ELU)\n",
    "covn.fit(trainloader, testloader, epochs=20, lr=1e-4, weight_decay=1e-4, opt_func=torch.optim.Adam, verbose=True)\n",
    "\n",
    "# NOTE: Easist way to figure out first layer size for full_layer_size: \n",
    "# enter the convolutional layer sizes you'd like, plus any number for\n",
    "# the full layers, and get the proper full layer size from the resulting error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP neural network trained on randomized Dataset loaded from numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network design:  EasyTorchMLP(\n",
      "  (net): ModuleDict(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (layer_0): Linear(in_features=100, out_features=2048, bias=True)\n",
      "    (activation_0): ReLU(inplace=True)\n",
      "    (layer_1): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (activation_1): ReLU(inplace=True)\n",
      "    (layer_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (activation_2): ReLU(inplace=True)\n",
      "    (output): Linear(in_features=512, out_features=5, bias=True)\n",
      "  )\n",
      ")\n",
      "#### Start training: ####\n",
      "Device: cuda\n",
      "Training...\n",
      "Epoch 0: Train loss: 0.855, accuracy: 0.848 :: Test loss: 0.354 accuracy: 0.998\n",
      "Epoch 1: Train loss: 0.209, accuracy: 0.999 :: Test loss: 0.128 accuracy: 1.000\n",
      "Epoch 2: Train loss: 0.093, accuracy: 1.000 :: Test loss: 0.072 accuracy: 1.000\n",
      "Epoch 3: Train loss: 0.057, accuracy: 1.000 :: Test loss: 0.049 accuracy: 1.000\n",
      "Epoch 4: Train loss: 0.040, accuracy: 1.000 :: Test loss: 0.037 accuracy: 1.000\n",
      "Training finished.\n",
      "Final train loss: 0.040 :: accuracy: 1.000\n",
      "Final test loss: 0.037 :: accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import dataloading\n",
    "from easy_torch import EasyTorchMLP\n",
    "\n",
    "X, y = make_blobs(n_samples=20000, n_features=100, centers=5, cluster_std=10) #, random_state=2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7) #, random_state=2)\n",
    "trainloader, testloader = dataloading.from_np(X_train, X_test, y_train, y_test, batch_size=64)\n",
    "\n",
    "# data shape to find number of features and classes\n",
    "num_rows, num_cols = X_train.shape\n",
    "unique_y = np.unique(y_train) # i.e. classes\n",
    "\n",
    "# initialize model, train and test\n",
    "mlp = EasyTorchMLP(num_cols, len(unique_y), hidden_layer_sizes=(2048,1024,512), residual_inserts=None)\n",
    "mlp.fit(trainloader, testloader, epochs=5, lr=1e-3, weight_decay=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#(example save and load of the MLP model:)\n",
    "model = mlp\n",
    "torch.save(model.state_dict(), \"./model/model.torch\")\n",
    "\n",
    "model.load_state_dict(torch.load(\"./model/model.torch\"))\n",
    "model.eval()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26c9e74da71a910508dcf457408e75022f81762502824a4d313a5cb933995f87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
