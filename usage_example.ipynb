{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## easy_torch usage examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional neural network trained on CIFAR100 Dataset loaded from torchvision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### CIFAR100 ################\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataset classes : \n",
      " ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# import CIFAR100 Dataset\n",
    "print('######### CIFAR100 ################')\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                    download=True, transform=transform)\n",
    "\n",
    "# convert to DataLoaders\n",
    "batch_size = 64\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "print(\"Dataset classes : \\n\",trainset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network design:  Sequential(\n",
      "  (conv_layer_1): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batchNorm_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activationC_1): ELU(alpha=1.0, inplace=True)\n",
      "  (conv_layer_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batchNorm_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activationC_2): ELU(alpha=1.0, inplace=True)\n",
      "  (maxPool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout_2): Dropout(p=0.5, inplace=False)\n",
      "  (conv_layer_3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batchNorm_3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activationC_3): ELU(alpha=1.0, inplace=True)\n",
      "  (conv_layer_4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batchNorm_4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activationC_4): ELU(alpha=1.0, inplace=True)\n",
      "  (maxPool_4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout_4): Dropout(p=0.5, inplace=False)\n",
      "  (conv_layer_5): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batchNorm_5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activationC_5): ELU(alpha=1.0, inplace=True)\n",
      "  (conv_layer_6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batchNorm_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activationC_6): ELU(alpha=1.0, inplace=True)\n",
      "  (maxPool_6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout_6): Dropout(p=0.5, inplace=False)\n",
      "  (conv_layer_7): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batchNorm_7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activationC_7): ELU(alpha=1.0, inplace=True)\n",
      "  (conv_layer_8): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batchNorm_8): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activationC_8): ELU(alpha=1.0, inplace=True)\n",
      "  (maxPool_8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout_8): Dropout(p=0.5, inplace=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (output): Linear(in_features=4096, out_features=100, bias=True)\n",
      ")\n",
      "#### Start training: ####\n",
      "Device: cuda\n",
      "Training...\n",
      "Epoch 0: Train loss: 3.637, accuracy: 0.152 :: Test loss: 2.995 accuracy: 0.253\n",
      "Epoch 1: Train loss: 2.775, accuracy: 0.299 :: Test loss: 2.499 accuracy: 0.364\n",
      "Epoch 2: Train loss: 2.373, accuracy: 0.380 :: Test loss: 2.214 accuracy: 0.420\n",
      "Epoch 3: Train loss: 2.113, accuracy: 0.440 :: Test loss: 1.958 accuracy: 0.476\n",
      "Epoch 4: Train loss: 1.927, accuracy: 0.478 :: Test loss: 1.872 accuracy: 0.495\n",
      "Epoch 5: Train loss: 1.777, accuracy: 0.515 :: Test loss: 1.731 accuracy: 0.531\n",
      "Epoch 6: Train loss: 1.646, accuracy: 0.544 :: Test loss: 1.655 accuracy: 0.539\n",
      "Epoch 7: Train loss: 1.526, accuracy: 0.575 :: Test loss: 1.622 accuracy: 0.559\n",
      "Epoch 8: Train loss: 1.437, accuracy: 0.596 :: Test loss: 1.549 accuracy: 0.576\n",
      "Epoch 9: Train loss: 1.355, accuracy: 0.615 :: Test loss: 1.551 accuracy: 0.573\n",
      "Training finished.\n",
      "Final train loss: 1.355  accuracy: 0.615\n",
      "Final test loss: 1.551  :: accuracy: 0.573\n"
     ]
    }
   ],
   "source": [
    "# Train a convolutional network on the CIFAR100 Dataset\n",
    "from easy_torch import EasyTorchConv\n",
    "\n",
    "# create the convolutional network: first layer is the channel number\n",
    "covn = EasyTorchConv(len(trainset.classes), conv_layer_sizes=(3,256,256,512,512,1024,1024,1024,1024),\n",
    "                                        full_layer_sizes=(4096,), batch_norm=True)\n",
    "covn.fit(trainloader, testloader, epochs=10, lr=1e-4, weight_decay=1e-4, opt_func=torch.optim.Adam, verbose=True)\n",
    "\n",
    "# NOTE: Easy way to figure out first layer size for full_layer_size: \n",
    "# enter the convolutional layer sizes you'd like,\n",
    "# plus any number for the full layers, and run for the size error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP neural network trained on randomized Dataset loaded from numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network design:  Sequential(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (input_layer): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation_input): ReLU(inplace=True)\n",
      "  (hidden_layer_1): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (activation_1): ReLU(inplace=True)\n",
      "  (output): Linear(in_features=100, out_features=5, bias=True)\n",
      ")\n",
      "#### Start training: ####\n",
      "Device: cuda\n",
      "Training...\n",
      "Epoch 0: Train loss: 0.380, accuracy: 0.888 :: Test loss: 0.085 accuracy: 0.989\n",
      "Epoch 1: Train loss: 0.028, accuracy: 1.000 :: Test loss: 0.047 accuracy: 0.992\n",
      "Epoch 2: Train loss: 0.013, accuracy: 1.000 :: Test loss: 0.035 accuracy: 0.992\n",
      "Epoch 3: Train loss: 0.008, accuracy: 1.000 :: Test loss: 0.029 accuracy: 0.994\n",
      "Epoch 4: Train loss: 0.006, accuracy: 1.000 :: Test loss: 0.025 accuracy: 0.995\n",
      "Epoch 5: Train loss: 0.005, accuracy: 1.000 :: Test loss: 0.023 accuracy: 0.995\n",
      "Epoch 6: Train loss: 0.004, accuracy: 1.000 :: Test loss: 0.021 accuracy: 0.996\n",
      "Epoch 7: Train loss: 0.003, accuracy: 1.000 :: Test loss: 0.019 accuracy: 0.996\n",
      "Epoch 8: Train loss: 0.003, accuracy: 1.000 :: Test loss: 0.018 accuracy: 0.996\n",
      "Epoch 9: Train loss: 0.002, accuracy: 1.000 :: Test loss: 0.017 accuracy: 0.996\n",
      "Training finished.\n",
      "Final train loss: 0.002  accuracy: 1.000\n",
      "Final test loss: 0.017  :: accuracy: 0.996\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import dataloading\n",
    "from easy_torch import EasyTorchMLP\n",
    "\n",
    "X, y = make_blobs(n_samples=2000, n_features=100, centers=5, cluster_std=10) #, random_state=95)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7) #, random_state=95)\n",
    "trainloader, testloader = dataloading.from_np(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# data shape to find number of features and classes\n",
    "num_rows, num_cols = X_train.shape\n",
    "unique_y = np.unique(y_train) # i.e. classes\n",
    "\n",
    "# initialize model, train and test\n",
    "mlp = EasyTorchMLP(num_cols, len(unique_y), hidden_layer_sizes=(200,100))\n",
    "mlp.fit(trainloader, testloader, epochs=10, lr=1e-3, weight_decay=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#(example save and load of the MLP model:)\n",
    "model = mlp\n",
    "torch.save(model.state_dict(), \"./model/model.torch\")\n",
    "\n",
    "model.load_state_dict(torch.load(\"./model/model.torch\"))\n",
    "model.eval()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26c9e74da71a910508dcf457408e75022f81762502824a4d313a5cb933995f87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
